axis.line = element_blank(),
axis.ticks = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.title = element_blank()
)
states.tree.scaled <- cutree(scaled.clust, 3)
states.tree.scaled
data_frame(state = tolower(names(states.tree.scaled)), tree.group = states.tree.scaled) %>%
left_join(map_data("state"), by = c("state" = "region")) %>%
ggplot(., aes(x=long, y=lat, group=group))+
coord_fixed(1.3)+
geom_polygon(color="black", fill="grey")+
geom_polygon(aes(fill=factor(tree.group)), color="white")+
labs(title = "Trimmed Tree Groupings", fill="Group Number", x=NULL, y=NULL)+
theme(
axis.text = element_blank(),
axis.line = element_blank(),
axis.ticks = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.title = element_blank()
)
data_frame(state = tolower(names(states.tree.scaled)), tree.group = states.tree.scaled) %>%
left_join(map_data("state"), by = c("state" = "region")) %>%
ggplot(., aes(x=long, y=lat, group=group))+
coord_fixed(1.3)+
geom_polygon(color="black", fill="grey")+
geom_polygon(aes(fill=factor(tree.group)), color="white")+
labs(title = "Trimmed Tree Groupings when Data is Scaled", fill="Group Number", x=NULL, y=NULL)+
theme(
axis.text = element_blank(),
axis.line = element_blank(),
axis.ticks = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.title = element_blank()
)
?USArrests
library(tidyverse)
attach(USArrests)
states <- row.names(USArrests)
map(USArrests, mean)
map(USArrests, var)
dist(USArrests[c(1,2),])
dist(USArrests[c(1,2),], method = "maximum")
dist(USArrests[c(1,2),], method = "manhattan")
dist(USArrests[c(1,2),], method = "binary")
set.seed(2)
# Use maximum distance method (complete)
hc.complete <- hclust(dist(USArrests), method = "complete")
# Plot the result
plot(hc.complete)
# Group hc.complete into 3 groups
states.tree <- cutree(hc.complete, 3)
states.tree
# Plot the groups onto a map
library(maps)
data_frame(state = tolower(names(states.tree)), tree.group = states.tree) %>%
left_join(map_data("state"), by = c("state" = "region")) %>%
ggplot(., aes(x=long, y=lat, group=group))+
coord_fixed(1.3)+
geom_polygon(color="black", fill="grey")+
geom_polygon(aes(fill=factor(tree.group)), color="white")+
labs(title = "Trimmed Tree Groupings", fill="Group Number", x=NULL, y=NULL)+
theme(
axis.text = element_blank(),
axis.line = element_blank(),
axis.ticks = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.title = element_blank()
)
# Scale the data
sd.data <- scale(USArrests)
# Run the clustering on scaled data
scaled.clust <- hclust(dist(sd.data), method = "complete")
plot(scaled.clust)
states.tree.scaled <- cutree(scaled.clust, 3)
states.tree.scaled
# Which states are in the same group as before?
cutree(hc.complete, 3) == cutree(scaled.clust, 3)
# Visaulize the new groups
data_frame(state = tolower(names(states.tree.scaled)), tree.group = states.tree.scaled) %>%
left_join(map_data("state"), by = c("state" = "region")) %>%
ggplot(., aes(x=long, y=lat, group=group))+
coord_fixed(1.3)+
geom_polygon(color="black", fill="grey")+
geom_polygon(aes(fill=factor(tree.group)), color="white")+
labs(title = "Trimmed Tree Groupings when Data is Scaled", fill="Group Number", x=NULL, y=NULL)+
theme(
axis.text = element_blank(),
axis.line = element_blank(),
axis.ticks = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.title = element_blank()
)
set.seed(2)
x=matrix(rnorm(50*2), ncol=2)
x[1:25,1] <- x[1:25,1]+3
x[1:25,2] <- x[1:25,2]-4
# Set centers (k) = 2
km.out <- kmeans(x, centers = 2, nstart = 20)
km.out$cluster
set.seed(4)
km.out3 <- kmeans(x, 3, nstart = 20)
km.out3
km.out3$tot.withinss
# Try another separation
set.seed(1)
km.out4 <- kmeans(x, 3, nstart = 1)
km.out4
km.out4$tot.withinss
library(tidyverse)
attach(USArrests)
states <- row.names(USArrests)
map(USArrests, mean)
library(tidyverse)
attach(USArrests)
states <- row.names(USArrests)
map(USArrests, mean)
map(USArrests, var)
dist(USArrests[c(1,2),])
dist(USArrests[c(1,2),], method = "maximum")
dist(USArrests[c(1,2),], method = "manhattan")
dist(USArrests[c(1,2),], method = "binary")
set.seed(2)
# Use maximum distance method (complete)
hc.complete <- hclust(dist(USArrests), method = "complete")
# Plot the result
plot(hc.complete)
# Group hc.complete into 3 groups
states.tree <- cutree(hc.complete, 3)
states.tree
# Plot the groups onto a map
library(maps)
data_frame(state = tolower(names(states.tree)), tree.group = states.tree) %>%
left_join(map_data("state"), by = c("state" = "region")) %>%
ggplot(., aes(x=long, y=lat, group=group))+
coord_fixed(1.3)+
geom_polygon(color="black", fill="grey")+
geom_polygon(aes(fill=factor(tree.group)), color="white")+
labs(title = "Trimmed Tree Groupings", fill="Group Number", x=NULL, y=NULL)+
theme(
axis.text = element_blank(),
axis.line = element_blank(),
axis.ticks = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.title = element_blank()
)
# Scale the data
sd.data <- scale(USArrests)
# Run the clustering on scaled data
scaled.clust <- hclust(dist(sd.data), method = "complete")
plot(scaled.clust)
states.tree.scaled <- cutree(scaled.clust, 3)
states.tree.scaled
# Which states are in the same group as before?
cutree(hc.complete, 3) == cutree(scaled.clust, 3)
# Visaulize the new groups
data_frame(state = tolower(names(states.tree.scaled)), tree.group = states.tree.scaled) %>%
left_join(map_data("state"), by = c("state" = "region")) %>%
ggplot(., aes(x=long, y=lat, group=group))+
coord_fixed(1.3)+
geom_polygon(color="black", fill="grey")+
geom_polygon(aes(fill=factor(tree.group)), color="white")+
labs(title = "Trimmed Tree Groupings when Data is Scaled", fill="Group Number", x=NULL, y=NULL)+
theme(
axis.text = element_blank(),
axis.line = element_blank(),
axis.ticks = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.title = element_blank()
)
set.seed(2)
x=matrix(rnorm(50*2), ncol=2)
x[1:25,1] <- x[1:25,1]+3
x[1:25,2] <- x[1:25,2]-4
# Set centers (k) = 2
km.out <- kmeans(x, centers = 2, nstart = 20)
km.out$cluster
set.seed(4)
km.out3 <- kmeans(x, 3, nstart = 20)
km.out3
km.out3$tot.withinss
# Try another separation
set.seed(1)
km.out4 <- kmeans(x, 3, nstart = 1)
km.out4
km.out4$tot.withinss
library(arules)
library(arulesViz)
data(Groceries)
rules <- apriori(Groceries, parameter = list(support = 0.001, confidence = 0.5))
rules
plot(rules)
plot(rules, measure = c("support", "lift"), shading = "confidence", interactive = T)
plot(rules, method = "grouped", control = list(k=30), interactive = T)
plot(rules, method = "grouped", control = list(k=30), interactive = T)
plot(rules, measure = c("support", "lift"), shading = "confidence", interactive = T)
plot(rules, measure = c("support", "lift"), shading = "confidence", interactive = T)
library(repurrrsive)
nrow(sw_people)
str(sw_people)
class(sw_people)
sw_people[1]
sw_people[[1]]
length(sw_people)
length(sw_people[1])
length(sw_people[[1]])
sw_people[[1]]
length(sw_people[[1]])
luke <- sw_people[[1]]
luke
luke$starships
length(luke$starships)
library(purrr)
map(luke$starships, length)
map(sw_people, ~ length(.x$starships) )
planet_lookup <- map_chr(sw_planets, "name")  %>%
set_names(map_chr(sw_planets, "url"))
planet_lookup
luke$homeworld
map(sw_people,~ .x$homeworld)
luke$homeworld
planet_lookup[luke$homeworld]
map(sw_people, ~ planet_lookup[.x$homeworld])
luke$mass / (luke$height^2)
luke$height
luke$mass
as.numeric(luke$mass) / as.numeric(luke$height^2)
as.numeric(luke$height^2)
as.numeric(luke$mass) / as.numeric(luke$height)^2
as.numeric(luke$mass) / (as.numeric(luke$height)^2)
as.numeric(luke$mass) / ((as.numeric(luke$height)/100)^2)
map(sw_people, ~ as.numeric(.x$mass) / ((as.numeric(.x$height)/100)^2))
warnings()
sw_people <- sw_people %>% set_names(map_chr(sw_people, "name"))
map(sw_people, ~ length(.x[["starships"]]))
map_int(sw_people, ~ length(.x[["starships"]]))
map(sw_people, ~ .x[["hair_color"]])
map_chr(sw_people, ~ .x[["hair_color"]])
map(sw_people, ~ .x[["gender"]] == "male")
map_lgl(sw_people, ~ .x[["gender"]] == "male")
map(sw_people, ~ .x[["mass"]])
map_num(sw_people, ~ .x[["mass"]])
map_dbl(sw_people, ~ .x[["mass"]])
map_chr(sw_people, ~ .x[["mass"]])
map_chr(sw_people, ~ .x[["mass"]]) %>%
readr::parse_number(na = "unknown")
map_chr(sw_people, ~ .x[["mass"]]) %>%
readr::parse_number(na = "unknown") %>% hist
sw_films
sw_films[["characters"]]
sw_films["The Empire Strikes Back"]
sw_films[6]
sw_films[[6]]
sw_films[[6]]$characters
map(sw_films, .x$characters)
map(sw_films, .x[[.]]$characters)
map(sw_films, ~ .x[[.]]$characters)
map(sw_films, ~ .x[[]]$characters)
sw_films[[1]]$characters
map(sw_films, ~ .x$characters)
map(sw_films, ~ .x$characters) %>% map_int(length)
map(sw_films, ~ .x$characters) %>%
set_names(map_chr(sw_films, "title")) %>% map_int(length)
gap_split_small <- gap_split[1:10]
countries <- names(gap_split_small)
gap_split_small
countries
gap_split_small[[1]]
library(tidyverse)
gap_split_small[[1]] %>%
ggplot(., aes(x=year, y=lifeExp))+
geom_line()
gap_split_small[[1]] %>%
ggplot(., aes(x=year, y=lifeExp))+
geom_line()+
ggtitle(countries[1])
walk2(gap_split_small, countries, ggplot, aes(x=year, y=lifeExp))
walk2(gap_split_small, countries, ggplot)
walk2(gap_split_small, countries, ggplot, mapping = aes(year, LifeExp))
walk2(gap_split_small, countries, ggplot, mapping = aes(year, LifeExp))+
geom_line()
map2(gap_split_small, countries, ggplot, mapping = aes(year, LifeExp)) +
geom_line()
map2(gap_split_small, countries, ggplot, mapping = aes(year, LifeExp))
map2(gap_split_small, countries, ggplot, .x, mapping = aes(year, LifeExp))
ggplot(gap_split_small[[1]], aes(x=year, y=lifeExp))+
geom_line()+
ggtitle(countries[1])
map2(gap_split_small, countries, ~ ggplot(.x, aes(x=year, y=lifeExp))+
geom_line()+
ggtitle(.y))
plots <- map2(gap_split_small, countries, ~ ggplot(.x, aes(x=year, y=lifeExp))+
geom_line()+
ggtitle(.y))
walk2(.x = plots, .y=countries, ~ ggsave(filename = paste0(.y, ".pdf"), plot = .x))
library("arules", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("arulesSequences", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("arulesViz", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library(neuralnet)
library(ISLR)
attach(College)
str(College)
College[,-1]
View(College[,-1])
mins <- apply(College[,-1], 2, min)
mins
maxs <- apply(College[,-1], 2, max)
maxs
rescaled.data <- scale(College[,-1], center=mins, scale = maxs-mins)
rescaled.data
apply(rescaled.data, 2, min)
apply(rescaled.data, 2, max)
?sample.split
??sample.split
splitpoint <- caTools::sample.split(College$Private, SplitRatio = 0.7)
test <- subset(College, split==TRUE)
test <- subset(College, splitpoint==TRUE)
train <- subset(College, splitpoint==TRUE)
test <- subset(College, splitpoint==FALSE)
nrow(train)/777
View(train)
nn.q1 <- neuralnet(formula = Private ~ ., data = train, c(10), linear.output = F)
names(rescaled.data)
rescaled.data
names(rescaled.data)
names(College)
names(College)[-1]
form <- paste(names(College)[-1], collapse = "+")
form <- paste("Private ~ ", form)
form
View(train)
form <- as.formula(form)
nn.q1 <- neuralnet(formula = form, data = train, c(10), linear.output = F)
nn.q1 <- neuralnet(formula = form, data = train, c(5), linear.output = F)
nn.q1 <- neuralnet(formula = form, data = train, c(10))
View(train)
train <- subset(rescaled.data, splitpoint==TRUE)
test <- subset(rescaled.data, splitpoint==FALSE)
nn.q1 <- neuralnet(formula = form, data = train, c(10))
nn.q1 <- neuralnet(formula = form, data = train, c(10), linear.output = F)
sample(rescaled.data, size = nrow(College)*.7, replace = F)
View(train)
str(train)
train['Apps']
train[,'Apps']
splitpoint
College$Private[splitpoint]
train[,'Private'] <- College$Private[splitpoint]
train[,'Private'] <- College$Private[splitpoint==T]
College$Private[splitpoint==T]
cbind(College$Private[splitpoint==T], train)
train <- data.frame(Private = College$Private[splitpoint==T], train)
View(train)
nn.q1 <- neuralnet(formula = form, data = train, c(10), linear.output = F)
rescaled.data <- as.data.frame(scale(College[,-1], center=mins, scale = maxs-mins))
apply(rescaled.data, 2, min)
apply(rescaled.data, 2, max)
set.seed(101)
View(rescaled.data)
splitpoint <- caTools::sample.split(College$Private, SplitRatio = 0.7)
train <- subset(rescaled.data, splitpoint==TRUE)
test <- subset(rescaled.data, splitpoint==FALSE)
View(train)
nn.q1 <- neuralnet(formula = form, data = train, c(10), linear.output = F)
?neuralnet
nn.q1 <- neuralnet(formula = form, data = train, hidden = 10, linear.output = F)
train <- data.frame(Private = College$Private[splitpoint==T], train)
View(train)
test <- data.frame(Private = College$Private[splitpoint==F], train)
test <- data.frame(Private = College$Private[splitpoint==F], test)
nn.q1 <- neuralnet(formula = form, data = train, hidden = 10, linear.output = F)
nn.q1 <- neuralnet(formula = form, data = train, hidden = c(10), linear.output = F)
nn.q1 <- neuralnet(formula = form, data = train, hidden = c(10), linear.output = T)
nn.q1 <- neuralnet(formula = form, train, hidden = c(10), linear.output = F)
neuralnet(formula = form, train, hidden = c(10), linear.output = F)
names(rescaled.data)
names(rescaled.data)
form <- paste(names(rescaled.data), collapse = "+")
form <- paste("Private ~ ", form)
form <- as.formula(form)
form
nn.q1 <- neuralnet(formula = form, train, hidden = c(10), linear.output = F)
splitpoint <- caTools::sample.split(rescaled.data$Private, SplitRatio = 0.7)
splitpoint <- caTools::sample.split(College$Private, SplitRatio = 0.7)
train <- subset(rescaled.data, splitpoint==TRUE)
test <- subset(rescaled.data, splitpoint==FALSE)
train <- data.frame(Private = College$Private[splitpoint==T], train)
test <- data.frame(Private = College$Private[splitpoint==F], test)
nn.q1 <- neuralnet(formula = form, train, hidden = c(10), linear.output = F)
form
train$Private
train <- data.frame(Private = ifelse(College$Private[splitpoint==T]=="Yes", 1, 0), train)
nn.q1 <- neuralnet(formula = form, train, hidden = c(10), linear.output = F)
test <- data.frame(Private = ifelse(College$Private[splitpoint==F]=="Yes", 1, 0), test)
plot(nn.q1)
View(test)
# Normalize the data between 0 and 1
# First get minimums and maximum values
mins <- apply(College[,-1], 2, min)
maxs <- apply(College[,-1], 2, max)
# Rescale the data so that it's between 0 and 1
rescaled.data <- as.data.frame(scale(College[,-1], center=mins, scale = maxs-mins))
apply(rescaled.data, 2, min)
apply(rescaled.data, 2, max)
set.seed(101)
# Split the data into training and test, 70% in training
splitpoint <- caTools::sample.split(College$Private, SplitRatio = 0.7)
train <- subset(rescaled.data, splitpoint==TRUE)
test <- subset(rescaled.data, splitpoint==FALSE)
train <- data.frame(Private = ifelse(College$Private[splitpoint==T]=="Yes", 1, 0), train)
test <- data.frame(Private = ifelse(College$Private[splitpoint==F]=="Yes", 1, 0), test)
# Create a formula for the neural network code
form <- paste(names(rescaled.data), collapse = "+")
form <- paste("Private ~ ", form)
form <- as.formula(form)
# Train the neural network
nn.q1 <- neuralnet(formula = form, train, hidden = c(10), linear.output = F)
plot(nn.q1)
pred.nn1 <- compute(nn.q1, test[,-1])
pred.probs.nn1 <- pred.nn1$net.result
pred.probs.nn1
pred.yesno.q1 <- ifelse(round(pred.probs.nn1,0)==1, "Yes", "No")
pred.yesno.q1
actual <- ifelse(test$Private==1, "Yes", "No")
table(pred.yesno.q1, actual)
mean(pred.yesno.q1==actual)
table(pred.yesno.q1, actual)
mean(actual=="Yes")
table(pred.yesno.q1, actual)
nn.q2 <- neuralnet(formula = form, train, hidden = c(10, 10, 10), linear.output = F)
plot(nn.q2)
pred.nn2 <- compute(nn.q2, test[,-1])
pred.probs.nn2 <- pred.nn2$net.result
pred.yesno.q2 <- ifelse(round(pred.probs.nn2,0)==1, "Yes", "No")
actual <- ifelse(test$Private==1, "Yes", "No")
table(pred.yesno.q1, actual)
table(pred.yesno.q2, actual)
mean(pred.yesno.q2==actual)
table(pred.yesno.q2, actual)
library(neuralnet)
library(ISLR)
attach(College)
str(College)
# Normalize the data between 0 and 1
# First get minimums and maximum values
mins <- apply(College[,-1], 2, min)
maxs <- apply(College[,-1], 2, max)
# Rescale the data so that it's between 0 and 1
rescaled.data <- as.data.frame(scale(College[,-1], center=mins, scale = maxs-mins))
apply(rescaled.data, 2, min)
apply(rescaled.data, 2, max)
set.seed(101)
# Split the data into training and test, 70% in training
splitpoint <- caTools::sample.split(College$Private, SplitRatio = 0.7)
train <- subset(rescaled.data, splitpoint==TRUE)
test <- subset(rescaled.data, splitpoint==FALSE)
train <- data.frame(Private = ifelse(College$Private[splitpoint==T]=="Yes", 1, 0), train)
test <- data.frame(Private = ifelse(College$Private[splitpoint==F]=="Yes", 1, 0), test)
# Create a formula for the neural network code
form <- paste(names(rescaled.data), collapse = "+")
form <- paste("Private ~ ", form)
form <- as.formula(form)
# Train the neural network
nn.q1 <- neuralnet(formula = form, train, hidden = c(10), linear.output = F)
plot(nn.q1)
# Compute the predicted probabilities
pred.nn1 <- compute(nn.q1, test[,-1])
pred.probs.nn1 <- pred.nn1$net.result
# Create a confusion matrix
pred.yesno.q1 <- ifelse(round(pred.probs.nn1,0)==1, "Yes", "No")
actual <- ifelse(test$Private==1, "Yes", "No")
table(pred.yesno.q1, actual)
# mean(pred.yesno.q1==actual) # Accuracy
# mean(actual=="Yes")
# Redo the neural network with multiple hidden layers
nn.q2 <- neuralnet(formula = form, train, hidden = c(10, 10, 10), linear.output = F)
plot(nn.q2)
# Compute the predicted probabilities
pred.nn2 <- compute(nn.q2, test[,-1])
pred.probs.nn2 <- pred.nn2$net.result
# Create a confusion matrix
pred.yesno.q2 <- ifelse(round(pred.probs.nn2,0)==1, "Yes", "No")
actual <- ifelse(test$Private==1, "Yes", "No")
table(pred.yesno.q2, actual)
# mean(pred.yesno.q2==actual)
iris
College
attitude
ISLR::OJ
summary(ISLR::OJ)
library(ISLR)
dat <- OJ
View(dat)
mod1 <- glm(Purchase ~ ., data=dat, family = "binomial")
summary(mod1)
mod1.pred <- predict.glm(mod1)
mod1.pred <- predict.glm(mod1, type = "response")
summary(mod1.pred)
install.packages('plotly')
licence()
library(shiny)
runExample("01_hello")
install.packages("BTYD")
install.packages("BTYDplus")
setwd("~/Documents/Github/blog")
